#!/usr/bin/env python
# mrcepid-collapsevariants 0.0.1
# Generated by dx-app-wizard.
#
# Author: Eugene Gardner (eugene.gardner at mrc.epid.cam.ac.uk)
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import dxpy
from general_utilities.import_utils.file_handlers.input_file_handler import InputFileHandler
from general_utilities.mrc_logger import MRCLogger

from makebgen.chunker.chunking_helper import chunking_helper
from makebgen.process_bgen.bgen_multithread import process_batches, process_subjob_outputs

LOGGER = MRCLogger().get_logger()


#    LOGGER.info(f'Loaded dxpy.entrypoint module {loaded_module}')


@dxpy.entry_point('main')
def main(output_prefix: str, coordinate_file: str, make_bcf: bool, gene_dict: str,
         ideal_chunk_size: int) -> dict:
    """Main entry point into this applet. This function initiates the conversion of all bcf files for a given chromosome
    into a single .bgen file.

    Coordinate file must have the following columns:

        chrom   start   end     vcf_prefix      output_bcf      output_bcf_idx  output_vep      output_vep_idx

    :param output_prefix: Output prefix. Output file will be named <output_prefix>.bgen
    :param coordinate_file: A file containing the coordinates of all bcf files to be processed.
    :param make_bcf: Should a concatenated bcf be made in addition to the bgen?
    :param gene_dict: A file containing the gene dictionary to be used for chunking.
    :param ideal_chunk_size: The final size of the bgen file to be created. This will be used to structure the batches.
    :return: An output dictionary following DNANexus conventions.
    """
    if ideal_chunk_size < 3:
        raise ValueError("The size of the final BGEN files must be at least 3Mb in size. This is to ensure that we can"
                         "find non-exonic regions to chunk the BGEN files correctly. ")

    # start the file parser class and get the coordinates file
    # Get coordinate and gene files
    coordinates = InputFileHandler(coordinate_file)
    coordinate_path = coordinates.get_file_handle()

    gene_dict_file = InputFileHandler(gene_dict)
    gene_dict_path = gene_dict_file.get_file_handle()

    # Run chunking and generate BGEN chunk files
    chunked_files, log_files = chunking_helper(
        gene_dict=gene_dict_path,
        coordinate_path=coordinate_path,
        chunk_size=ideal_chunk_size,
    )

    LOGGER.info(f"Total number of batches: {len(chunked_files)}")

    batches = process_batches(chunked_files, make_bcf, output_prefix)

    LOGGER.info(f"All chunks done, merging...")

    final_output = process_subjob_outputs(batches, make_bcf, output_prefix)
    final_output['logs'] = log_files

    LOGGER.info(f"Finished processing all batches")

    return final_output


dxpy.run()
